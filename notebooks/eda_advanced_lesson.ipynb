{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Advanced Lesson "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation\n",
    "\n",
    "Covariance and correlation are two mathematical concepts which are commonly used in statistics. They are used to determine the relationship between two variables. The covariance is used to measure the linear relationship between two variables. On the other hand, the correlation is used to measure both the strength and direction of the _linear relationship_ between two variables.\n",
    "\n",
    "Covariance is a measure of how much two random variables vary together. It’s similar to variance, but where variance tells you how a single variable varies, covariance tells you how two variables vary together.\n",
    "\n",
    "Correlation (coefficient) is a _normalized_ measure of covariance that is easier to understand, as it provides quantitative measurements of the statistical dependence between two random variables. The correlation coefficient is a value that indicates the strength of the relationship between variables. The coefficient can take any values from -1 to 1. The interpretations of the values are:\n",
    "\n",
    "- **-1**: Perfect negative linear correlation\n",
    "- **-0.8**: Strong negative linear correlation\n",
    "- **-0.5**: Moderate negative linear correlation\n",
    "- **-0.2**: Weak negative linear correlation\n",
    "- **0**: No linear correlation\n",
    "- **0.2**: Weak positive linear correlation\n",
    "- **0.5**: Moderate positive linear correlation\n",
    "- **0.8**: Strong positive linear correlation\n",
    "- **1**: Perfect positive linear correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use DataFrames of stock prices and volumes obtained from Yahoo! Finance available in binary Python pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_pickle(\"../data/yahoo_price.pkl\")\n",
    "volume = pd.read_pickle(\"../data/yahoo_volume.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>27.990226</td>\n",
       "      <td>313.062468</td>\n",
       "      <td>113.304536</td>\n",
       "      <td>25.884104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>28.038618</td>\n",
       "      <td>311.683844</td>\n",
       "      <td>111.935822</td>\n",
       "      <td>25.892466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>27.592626</td>\n",
       "      <td>303.826685</td>\n",
       "      <td>111.208683</td>\n",
       "      <td>25.733566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>27.541619</td>\n",
       "      <td>296.753749</td>\n",
       "      <td>110.823732</td>\n",
       "      <td>25.465944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>27.724725</td>\n",
       "      <td>300.709808</td>\n",
       "      <td>111.935822</td>\n",
       "      <td>25.641571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-17</th>\n",
       "      <td>117.550003</td>\n",
       "      <td>779.960022</td>\n",
       "      <td>154.770004</td>\n",
       "      <td>57.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18</th>\n",
       "      <td>117.470001</td>\n",
       "      <td>795.260010</td>\n",
       "      <td>150.720001</td>\n",
       "      <td>57.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-19</th>\n",
       "      <td>117.120003</td>\n",
       "      <td>801.500000</td>\n",
       "      <td>151.259995</td>\n",
       "      <td>57.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-20</th>\n",
       "      <td>117.059998</td>\n",
       "      <td>796.969971</td>\n",
       "      <td>151.520004</td>\n",
       "      <td>57.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-21</th>\n",
       "      <td>116.599998</td>\n",
       "      <td>799.369995</td>\n",
       "      <td>149.630005</td>\n",
       "      <td>59.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        GOOG         IBM       MSFT\n",
       "Date                                                     \n",
       "2010-01-04   27.990226  313.062468  113.304536  25.884104\n",
       "2010-01-05   28.038618  311.683844  111.935822  25.892466\n",
       "2010-01-06   27.592626  303.826685  111.208683  25.733566\n",
       "2010-01-07   27.541619  296.753749  110.823732  25.465944\n",
       "2010-01-08   27.724725  300.709808  111.935822  25.641571\n",
       "...                ...         ...         ...        ...\n",
       "2016-10-17  117.550003  779.960022  154.770004  57.220001\n",
       "2016-10-18  117.470001  795.260010  150.720001  57.660000\n",
       "2016-10-19  117.120003  801.500000  151.259995  57.529999\n",
       "2016-10-20  117.059998  796.969971  151.520004  57.250000\n",
       "2016-10-21  116.599998  799.369995  149.630005  59.660000\n",
       "\n",
       "[1714 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>123432400</td>\n",
       "      <td>3927000</td>\n",
       "      <td>6155300</td>\n",
       "      <td>38409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>150476200</td>\n",
       "      <td>6031900</td>\n",
       "      <td>6841400</td>\n",
       "      <td>49749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>138040000</td>\n",
       "      <td>7987100</td>\n",
       "      <td>5605300</td>\n",
       "      <td>58182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>119282800</td>\n",
       "      <td>12876600</td>\n",
       "      <td>5840600</td>\n",
       "      <td>50559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>111902700</td>\n",
       "      <td>9483900</td>\n",
       "      <td>4197200</td>\n",
       "      <td>51197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-17</th>\n",
       "      <td>23624900</td>\n",
       "      <td>1089500</td>\n",
       "      <td>5890400</td>\n",
       "      <td>23830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18</th>\n",
       "      <td>24553500</td>\n",
       "      <td>1995600</td>\n",
       "      <td>12770600</td>\n",
       "      <td>19149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-19</th>\n",
       "      <td>20034600</td>\n",
       "      <td>116600</td>\n",
       "      <td>4632900</td>\n",
       "      <td>22878400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-20</th>\n",
       "      <td>24125800</td>\n",
       "      <td>1734200</td>\n",
       "      <td>4023100</td>\n",
       "      <td>49455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-21</th>\n",
       "      <td>22384800</td>\n",
       "      <td>1260500</td>\n",
       "      <td>4401900</td>\n",
       "      <td>79974200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AAPL      GOOG       IBM      MSFT\n",
       "Date                                               \n",
       "2010-01-04  123432400   3927000   6155300  38409100\n",
       "2010-01-05  150476200   6031900   6841400  49749600\n",
       "2010-01-06  138040000   7987100   5605300  58182400\n",
       "2010-01-07  119282800  12876600   5840600  50559700\n",
       "2010-01-08  111902700   9483900   4197200  51197400\n",
       "...               ...       ...       ...       ...\n",
       "2016-10-17   23624900   1089500   5890400  23830000\n",
       "2016-10-18   24553500   1995600  12770600  19149500\n",
       "2016-10-19   20034600    116600   4632900  22878400\n",
       "2016-10-20   24125800   1734200   4023100  49455600\n",
       "2016-10-21   22384800   1260500   4401900  79974200\n",
       "\n",
       "[1714 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute percent changes of the prices using a window function (we will explain window functions in the later section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-17</th>\n",
       "      <td>-0.000680</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>-0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-18</th>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>-0.026168</td>\n",
       "      <td>0.007690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-19</th>\n",
       "      <td>-0.002979</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>-0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-20</th>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>-0.004867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-21</th>\n",
       "      <td>-0.003930</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>-0.012474</td>\n",
       "      <td>0.042096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      GOOG       IBM      MSFT\n",
       "Date                                              \n",
       "2016-10-17 -0.000680  0.001837  0.002072 -0.003483\n",
       "2016-10-18 -0.000681  0.019616 -0.026168  0.007690\n",
       "2016-10-19 -0.002979  0.007846  0.003583 -0.002255\n",
       "2016-10-20 -0.000512 -0.005652  0.001719 -0.004867\n",
       "2016-10-21 -0.003930  0.003011 -0.012474  0.042096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = price.pct_change()\n",
    "\n",
    "returns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the correlation and covariance between the returns of `MSFT` and `IBM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.870655479703546e-05)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns[\"MSFT\"].cov(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.49976361144151144)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns[\"MSFT\"].corr(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the full (pair-wise) correlation or covariance matrix as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBM</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL      GOOG       IBM      MSFT\n",
       "AAPL  0.000277  0.000107  0.000078  0.000095\n",
       "GOOG  0.000107  0.000251  0.000078  0.000108\n",
       "IBM   0.000078  0.000078  0.000146  0.000089\n",
       "MSFT  0.000095  0.000108  0.000089  0.000215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407919</td>\n",
       "      <td>0.386817</td>\n",
       "      <td>0.389695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.407919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405099</td>\n",
       "      <td>0.465919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBM</th>\n",
       "      <td>0.386817</td>\n",
       "      <td>0.405099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.389695</td>\n",
       "      <td>0.465919</td>\n",
       "      <td>0.499764</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL      GOOG       IBM      MSFT\n",
       "AAPL  1.000000  0.407919  0.386817  0.389695\n",
       "GOOG  0.407919  1.000000  0.405099  0.465919\n",
       "IBM   0.386817  0.405099  1.000000  0.499764\n",
       "MSFT  0.389695  0.465919  0.499764  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute pair-wise correlations between a DataFrame’s columns or rows with another Series or DataFrame. Passing a Series returns a Series with the correlation value computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL    0.386817\n",
       "GOOG    0.405099\n",
       "IBM     1.000000\n",
       "MSFT    0.499764\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.corrwith(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a DataFrame computes the correlations of matching column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL   -0.075565\n",
       "GOOG   -0.007067\n",
       "IBM    -0.204849\n",
       "MSFT   -0.092950\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.corrwith(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indexing (MultiIndex) allows you to have multiple (two or more) _index levels_ on an axis. It enables \"higher dimensional\" data in a lower dimensional data structure.\n",
    "\n",
    "You create a hierarchical index by simply passing a list of arrays to the index argument of a pandas DataFrame or Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #4472C4;\">Detail Explanation</span>\n",
    "\n",
    "**Think of Hierarchical Indexing like organizing a filing cabinet with multiple levels of organization.**\n",
    "\n",
    "Imagine you're organizing customer data for a retail business. Instead of having separate folders for each combination (like \"Electronics_January_Online\", \"Electronics_January_Store\", etc.), you create a hierarchical system:\n",
    "\n",
    "- **Level 1**: Product Category (Electronics, Clothing, Books)\n",
    "- **Level 2**: Month (January, February, March)  \n",
    "- **Level 3**: Sales Channel (Online, Store)\n",
    "\n",
    "This is exactly what pandas MultiIndex does - it creates multiple \"levels\" of indexing that work together.\n",
    "\n",
    "**Key Benefits of Hierarchical Indexing:**\n",
    "\n",
    "1. **Space Efficiency**: Instead of creating separate DataFrames for each group, you store everything in one structure\n",
    "2. **Easy Grouping**: You can quickly slice and dice data by any level\n",
    "3. **Natural Data Representation**: Many real-world datasets naturally have hierarchical structure\n",
    "\n",
    "**Real-World Applications:**\n",
    "\n",
    "- **Financial Data**: Company → Year → Quarter → Metric\n",
    "- **Sales Data**: Region → Store → Product Category → Month\n",
    "- **Survey Data**: Country → Age Group → Gender → Question\n",
    "- **Scientific Data**: Experiment → Trial → Measurement Type → Time\n",
    "\n",
    "**The Power of Partial Indexing:**\n",
    "\n",
    "When you have hierarchical indexing, you can \"zoom in\" at any level:\n",
    "- Want all data for a specific company? Use the first level\n",
    "- Want Q1 data across all companies? Use the second level\n",
    "- Want specific combinations? Use multiple levels together\n",
    "\n",
    "Think of it like a spreadsheet where you can collapse and expand grouped rows, but much more powerful and programmatic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of our hierarchical sales data:\n",
      "Region  Product      Month\n",
      "North   Electronics  Jan      8270\n",
      "                     Feb      1860\n",
      "                     Mar      6390\n",
      "        Clothing     Jan      6191\n",
      "                     Feb      6734\n",
      "                     Mar      7265\n",
      "        Books        Jan      1466\n",
      "                     Feb      5426\n",
      "                     Mar      6578\n",
      "South   Electronics  Jan      9322\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's create a practical example: Sales data for a retail company\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample sales data with hierarchical structure\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# Define the hierarchy levels\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "products = ['Electronics', 'Clothing', 'Books']\n",
    "months = ['Jan', 'Feb', 'Mar']\n",
    "\n",
    "# Create all combinations\n",
    "multi_index = pd.MultiIndex.from_product([regions, products, months], \n",
    "                                       names=['Region', 'Product', 'Month'])\n",
    "\n",
    "# Generate sample sales data\n",
    "sales_data = np.random.randint(1000, 10000, size=len(multi_index))\n",
    "\n",
    "# Create the hierarchical Series\n",
    "sales = pd.Series(sales_data, index=multi_index, name='Sales')\n",
    "\n",
    "print(\"Sample of our hierarchical sales data:\")\n",
    "print(sales.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sales in North region:\n",
      "Product      Month\n",
      "Electronics  Jan      8270\n",
      "             Feb      1860\n",
      "             Mar      6390\n",
      "Clothing     Jan      6191\n",
      "             Feb      6734\n",
      "             Mar      7265\n",
      "Books        Jan      1466\n",
      "             Feb      5426\n",
      "             Mar      6578\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Electronics sales across all regions:\n",
      "Region  Month\n",
      "North   Jan      8270\n",
      "        Feb      1860\n",
      "        Mar      6390\n",
      "South   Jan      9322\n",
      "        Feb      2685\n",
      "        Mar      1769\n",
      "East    Jan      5555\n",
      "        Feb      4385\n",
      "        Mar      7396\n",
      "West    Jan      3734\n",
      "        Feb      4005\n",
      "        Mar      5658\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "January sales across all regions and products:\n",
      "Region  Product    \n",
      "North   Electronics    8270\n",
      "        Clothing       6191\n",
      "        Books          1466\n",
      "South   Electronics    9322\n",
      "        Clothing       7949\n",
      "        Books          6051\n",
      "East    Electronics    5555\n",
      "        Clothing       9666\n",
      "        Books          3047\n",
      "West    Electronics    3734\n",
      "        Clothing       2899\n",
      "        Books          2528\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "North region, Electronics sales in February:\n",
      "1860\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Get all sales for the North region (Level 1 slicing)\n",
    "print(\"All sales in North region:\")\n",
    "print(sales['North'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Get Electronics sales across all regions (Level 2 slicing)\n",
    "print(\"Electronics sales across all regions:\")\n",
    "print(sales.xs('Electronics', level='Product'))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Get January sales across all regions and products (Level 3 slicing)\n",
    "print(\"January sales across all regions and products:\")\n",
    "print(sales.xs('Jan', level='Month'))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 4: Get specific combination - North region, Electronics, February\n",
    "print(\"North region, Electronics sales in February:\")\n",
    "print(sales['North', 'Electronics', 'Feb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Hierarchical Index:\n",
      "                          Sales  Profit_Margin  Units_Sold\n",
      "Region Product     Month                                  \n",
      "North  Electronics Jan     8270       0.236062          38\n",
      "                   Feb     1860       0.190100          24\n",
      "                   Mar     6390       0.102653          54\n",
      "       Clothing    Jan     6191       0.288440          74\n",
      "                   Feb     6734       0.212658          98\n",
      "                   Mar     7265       0.177083          80\n",
      "       Books       Jan     1466       0.103193          18\n",
      "                   Feb     5426       0.146179          97\n",
      "                   Mar     6578       0.148205          10\n",
      "South  Electronics Jan     9322       0.236653          17\n",
      "\n",
      "DataFrame shape: (36, 3)\n",
      "Index levels: 3\n",
      "Index names: ['Region', 'Product', 'Month']\n"
     ]
    }
   ],
   "source": [
    "# Let's create a DataFrame with hierarchical indexing\n",
    "# This is like having a spreadsheet with multiple row headers\n",
    "\n",
    "# Create additional metrics for our sales data\n",
    "profit_margin = np.random.uniform(0.1, 0.3, size=len(multi_index))\n",
    "units_sold = np.random.randint(10, 100, size=len(multi_index))\n",
    "\n",
    "# Create DataFrame with multiple columns\n",
    "sales_df = pd.DataFrame({\n",
    "    'Sales': sales_data,\n",
    "    'Profit_Margin': profit_margin,\n",
    "    'Units_Sold': units_sold\n",
    "}, index=multi_index)\n",
    "\n",
    "print(\"DataFrame with Hierarchical Index:\")\n",
    "print(sales_df.head(10))\n",
    "print(f\"\\nDataFrame shape: {sales_df.shape}\")\n",
    "print(f\"Index levels: {sales_df.index.nlevels}\")\n",
    "print(f\"Index names: {sales_df.index.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales by region:\n",
      "Region\n",
      "North    50180\n",
      "East     47392\n",
      "South    47124\n",
      "West     39271\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Average sales by product category:\n",
      "Product\n",
      "Clothing       6154.666667\n",
      "Electronics    5085.750000\n",
      "Books          4090.166667\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Average sales by month:\n",
      "Month\n",
      "Feb    4711.916667\n",
      "Jan    5556.500000\n",
      "Mar    5062.166667\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Top 5 region-product combinations by average sales:\n",
      "Region  Product    \n",
      "East    Clothing       7357.666667\n",
      "North   Clothing       6730.000000\n",
      "South   Clothing       5897.666667\n",
      "East    Electronics    5778.666667\n",
      "North   Electronics    5506.666667\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Common Business Questions with Hierarchical Data\n",
    "\n",
    "# 1. What are the total sales by region?\n",
    "print(\"Total sales by region:\")\n",
    "region_sales = sales_df.groupby(level='Region')['Sales'].sum().sort_values(ascending=False)\n",
    "print(region_sales)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Which product category performs best across all regions?\n",
    "print(\"Average sales by product category:\")\n",
    "product_sales = sales_df.groupby(level='Product')['Sales'].mean().sort_values(ascending=False)\n",
    "print(product_sales)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. Monthly trend analysis\n",
    "print(\"Average sales by month:\")\n",
    "monthly_sales = sales_df.groupby(level='Month')['Sales'].mean()\n",
    "print(monthly_sales)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 4. Best performing region-product combination\n",
    "print(\"Top 5 region-product combinations by average sales:\")\n",
    "region_product = sales_df.groupby(level=['Region', 'Product'])['Sales'].mean().sort_values(ascending=False).head()\n",
    "print(region_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Operations and Pro Tips:**\n",
    "\n",
    "1. **Level Selection**: Use `.xs()` for cross-section selection when you want specific values from inner levels\n",
    "2. **Multiple Level Grouping**: Group by multiple levels simultaneously for detailed analysis\n",
    "3. **Index Manipulation**: Use `swaplevel()` and `sort_index()` to reorganize your hierarchy\n",
    "4. **Memory Efficiency**: Hierarchical indexing is more memory-efficient than separate DataFrames\n",
    "\n",
    "**When to Use Hierarchical Indexing:**\n",
    "\n",
    "✅ **Good for:**\n",
    "- Time series data with multiple dimensions (stock prices by company and date)\n",
    "- Survey data with multiple categorical breakdowns\n",
    "- Financial data with multiple levels of aggregation\n",
    "- Any data where you frequently need to slice by different categorical combinations\n",
    "\n",
    "❌ **Avoid when:**\n",
    "- You have simple, flat data structures\n",
    "- You only ever need to access data by one dimension\n",
    "- Your data doesn't have natural hierarchical relationships\n",
    "\n",
    "**Key Takeaway:** Hierarchical indexing transforms complex, multi-dimensional data into an organized, easily queryable structure. It's like having a well-organized library where you can find books by author, genre, year, or any combination thereof!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a  1    0.382927\n",
       "   2    0.971712\n",
       "   3    0.848914\n",
       "b  1    0.721730\n",
       "   3    0.235985\n",
       "c  1    0.256068\n",
       "   2    0.040434\n",
       "d  2    0.710663\n",
       "   3    0.110891\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series(np.random.uniform(size=9),\n",
    "                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                 [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('a', 1),\n",
       "            ('a', 2),\n",
       "            ('a', 3),\n",
       "            ('b', 1),\n",
       "            ('b', 3),\n",
       "            ('c', 1),\n",
       "            ('c', 2),\n",
       "            ('d', 2),\n",
       "            ('d', 3)],\n",
       "           )"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use _partial indexing_ to select subsets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.721730\n",
       "3    0.235985\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b  1    0.721730\n",
       "   3    0.235985\n",
       "c  1    0.256068\n",
       "   2    0.040434\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"b\":\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #4472C4;\">Detail Explanation</span>\n",
    "\n",
    "**Understanding `data[\"b\":\"c\"]` - Slice Indexing with Hierarchical Data**\n",
    "\n",
    "This syntax is called **slice indexing** and it works like slicing a list, but with hierarchical index labels instead of numbers.\n",
    "\n",
    "**Think of it like this:**\n",
    "- Your hierarchical data is like a **sorted filing cabinet**\n",
    "- `data[\"b\":\"c\"]` means \"give me everything from folder 'b' up to and including folder 'c'\"\n",
    "- It's **inclusive** on both ends, so you get all 'b' entries AND all 'c' entries\n",
    "\n",
    "**What happens step by step:**\n",
    "1. **pandas looks at the first level** of your hierarchical index\n",
    "2. **Finds all entries starting from 'b'** (inclusive)\n",
    "3. **Continues until it reaches 'c'** (inclusive)\n",
    "4. **Returns all the data** in that range\n",
    "\n",
    "**Real-world analogy:**\n",
    "Imagine you have customer files organized alphabetically:\n",
    "- `customers[\"Brown\":\"Davis\"]` would give you all customers from Brown through Davis\n",
    "- This includes Brown, Carter, Chen, Davis, etc.\n",
    "\n",
    "**Key Points:**\n",
    "- ✅ **Both endpoints are included** ('b' and 'c' entries are both returned)\n",
    "- ✅ **Works with the first level** of hierarchical index by default\n",
    "- ✅ **Maintains the hierarchical structure** in the result\n",
    "- ⚠️ **Requires sorted index** for predictable results\n",
    "\n",
    "**Why is this useful?**\n",
    "- **Quick range selection**: Get data for consecutive categories\n",
    "- **Alphabetical filtering**: Perfect for name ranges, product codes, etc.\n",
    "- **Efficient**: Much faster than filtering with conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a clear example to demonstrate slice indexing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data with clear hierarchical structure\n",
    "np.random.seed(100)  # For consistent results\n",
    "companies = ['Apple', 'Google', 'Microsoft', 'Netflix', 'Tesla']\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "\n",
    "# Create hierarchical index\n",
    "multi_idx = pd.MultiIndex.from_product([companies, quarters], \n",
    "                                     names=['Company', 'Quarter'])\n",
    "\n",
    "# Create sample revenue data\n",
    "revenue = pd.Series(np.random.randint(10, 100, size=len(multi_idx)), \n",
    "                   index=multi_idx, name='Revenue_Billions')\n",
    "\n",
    "print(\"Complete dataset:\")\n",
    "print(revenue)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 1: Slice from Google to Netflix (inclusive)\n",
    "print(\"Example 1: revenue['Google':'Netflix']\")\n",
    "print(\"This gets ALL data from Google through Netflix (alphabetically)\")\n",
    "print(revenue['Google':'Netflix'])\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 2: Slice from Apple to Microsoft\n",
    "print(\"Example 2: revenue['Apple':'Microsoft']\") \n",
    "print(\"This gets ALL data from Apple through Microsoft\")\n",
    "print(revenue['Apple':'Microsoft'])\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Example 3: What if we want just one company?\n",
    "print(\"Example 3: revenue['Google'] (no slice, just single selection)\")\n",
    "print(\"This gets ALL quarters for Google only\")\n",
    "print(revenue['Google'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the original example to understand it better\n",
    "print(\"ORIGINAL EXAMPLE EXPLANATION:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# The original data has this structure:\n",
    "# Level 1: ['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd']\n",
    "# Level 2: [1, 2, 3, 1, 3, 1, 2, 2, 3]\n",
    "\n",
    "print(\"Original data structure:\")\n",
    "print(\"a  1    [some value]\")\n",
    "print(\"   2    [some value]\") \n",
    "print(\"   3    [some value]\")\n",
    "print(\"b  1    [some value]\")\n",
    "print(\"   3    [some value]\")  \n",
    "print(\"c  1    [some value]\")\n",
    "print(\"   2    [some value]\")\n",
    "print(\"d  2    [some value]\")\n",
    "print(\"   3    [some value]\")\n",
    "print()\n",
    "\n",
    "print(\"When you do data['b':'c'], you get:\")\n",
    "print(\"b  1    [some value]\")\n",
    "print(\"   3    [some value]\")  \n",
    "print(\"c  1    [some value]\")\n",
    "print(\"   2    [some value]\")\n",
    "print()\n",
    "print(\"Notice: It includes BOTH 'b' and 'c' groups entirely!\")\n",
    "print(\"This is different from data['b'] which would only give you the 'b' group.\")\n",
    "\n",
    "# Let's demonstrate with the actual data\n",
    "data_demo = pd.Series(np.random.uniform(size=9),\n",
    "                     index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                           [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ACTUAL DEMONSTRATION:\")\n",
    "print(\"Full data:\")\n",
    "print(data_demo)\n",
    "print(\"\\ndata['b':'c'] result:\")\n",
    "print(data_demo['b':'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Use Cases for Slice Indexing:**\n",
    "\n",
    "🎯 **Business Scenarios:**\n",
    "- `sales['January':'March']` - Get Q1 data\n",
    "- `customers['Brown':'Davis']` - Get customers in alphabetical range\n",
    "- `products['Electronics':'Furniture']` - Get product categories in range\n",
    "- `regions['Asia':'Europe']` - Get geographical regions\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "⚠️ **Order Matters**: Your index should be sorted for predictable results\n",
    "```python\n",
    "# Good: sorted index\n",
    "data.sort_index()['b':'d']  # Predictable results\n",
    "\n",
    "# Risky: unsorted index  \n",
    "data['b':'d']  # May give unexpected results\n",
    "```\n",
    "\n",
    "✅ **Best Practices:**\n",
    "1. **Always sort your index first** when using slice indexing\n",
    "2. **Use `.loc[]` for more explicit control**: `data.loc['b':'c']`\n",
    "3. **Remember it's inclusive** on both ends\n",
    "4. **Test with small examples** first to understand the behavior\n",
    "\n",
    "**Quick Comparison:**\n",
    "- `data['b']` → Only the 'b' group\n",
    "- `data['b':'c']` → Both 'b' and 'c' groups (range)\n",
    "- `data[['b', 'c']]` → Only 'b' and 'c' groups (specific selection, skips anything in between)\n",
    "\n",
    "**Key Takeaway:** Slice indexing (`['start':'end']`) is like selecting a range of chapters in a book - you get everything from the start chapter through the end chapter, including both endpoints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b  1    0.721730\n",
       "   3    0.235985\n",
       "d  2    0.710663\n",
       "   3    0.110891\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[\"b\", \"d\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select from \"inner\" level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    0.971712\n",
       "c    0.040434\n",
       "d    0.710663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indexing works on both axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ohio     Colorado\n",
       "    Green Red    Green\n",
       "a 1     0   1        2\n",
       "  2     3   4        5\n",
       "b 1     6   7        8\n",
       "  2     9  10       11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
    "                        index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
    "                        columns=[['Ohio', 'Ohio', 'Colorado'],\n",
    "                        ['Green', 'Red', 'Green']])\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting names on the axes work as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state      Ohio     Colorado\n",
       "color     Green Red    Green\n",
       "key1 key2                   \n",
       "a    1        0   1        2\n",
       "     2        3   4        5\n",
       "b    1        6   7        8\n",
       "     2        9  10       11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.index.names = [\"key1\", \"key2\"]\n",
    "frame.columns.names = [\"state\", \"color\"]\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.index.nlevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial indexing works on columns too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "color      Green  Red\n",
       "key1 key2            \n",
       "a    1         0    1\n",
       "     2         3    4\n",
       "b    1         6    7\n",
       "     2         9   10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[\"Ohio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to rearrange the order of the levels on an axis. The `swaplevel` method will swap the levels in the MultiIndex on a particular axis. The default is to swap the levels on the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key2</th>\n",
       "      <th>key1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>b</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>b</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state      Ohio     Colorado\n",
       "color     Green Red    Green\n",
       "key2 key1                   \n",
       "1    a        0   1        2\n",
       "2    a        3   4        5\n",
       "1    b        6   7        8\n",
       "2    b        9  10       11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.swaplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "color     Green  Red    Green\n",
       "state      Ohio Ohio Colorado\n",
       "key1 key2                    \n",
       "a    1        0    1        2\n",
       "     2        3    4        5\n",
       "b    1        6    7        8\n",
       "     2        9   10       11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.swaplevel(0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sort by a single level or subset of levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state      Ohio     Colorado\n",
       "color     Green Red    Green\n",
       "key1 key2                   \n",
       "a    1        0   1        2\n",
       "b    1        6   7        8\n",
       "a    2        3   4        5\n",
       "b    2        9  10       11"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Swap the levels on the rows then sort the index by level `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common to use one or more columns from a DataFrame as the row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>two</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>two</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>two</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b    c  d\n",
       "0  0  7  one  0\n",
       "1  1  6  one  1\n",
       "2  2  5  one  2\n",
       "3  3  4  two  0\n",
       "4  4  3  two  1\n",
       "5  5  2  two  2\n",
       "6  6  1  two  3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame({\"a\": range(7), \"b\": range(7, 0, -1), \n",
    "                      \"c\": [\"one\", \"one\", \"one\", \"two\", \"two\", \"two\", \"two\"], \n",
    "                      \"d\": [0, 1, 2, 0, 1, 2, 3]})\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_index` will return a new DataFrame using one or more of its columns as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = frame.set_index([\"c\", \"d\"])\n",
    "\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reset_index` does the opposite of `set_index` and turns the index back into a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to drop the columns when resetting index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Time Data\n",
    "\n",
    "Pandas is oriented towards working with arrays of dates, whether used as an axis index or a column.\n",
    "\n",
    "The `to_datetime` method parses may different kinds of date representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2011-07-06 12:00:00\", \"2011-08-06 00:00:00\"]\n",
    "\n",
    "pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses `NaT` (Not a Time) as null values for datetime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.to_datetime(dates + [None])\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Python uses the `datetime` module to handle date and time data. Pandas has a `Timestamp` object that is similar to the `datetime` object. Pandas also has a `Timedelta` object that is similar to the `timedelta` object.\n",
    "\n",
    "If you use `datetime` objects as index to a Series or DataFrame, Pandas will automatically convert them to `DatetimeIndex` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5), datetime(2011, 1, 7), datetime(2011, 1, 8), datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "\n",
    "ts = pd.Series(np.random.standard_normal(6), index=dates)\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other Series, arithmetic operations between differently indexed time series automatically align on the dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [::2] selects every second element\n",
    "ts + ts[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DatetimeIndex` is an array of `Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index by passing a `datetime`, `Timestamp` or `string` that is interpretable as a date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[datetime(2011, 1, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[pd.Timestamp(\"2011-01-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"2011-01-07\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even specify the year or year-month strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_range generate an array of dates\n",
    "longer_ts = pd.Series(np.random.standard_normal(1000), \n",
    "                      index=pd.date_range(\"2000-01-01\", periods=1000))\n",
    "\n",
    "longer_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_ts[\"2001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_ts[\"2001-05\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_ts[\"2001-05\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `date_range` to generate a Series of random values from 1-31st January 2023. Then slice the Series to return data from 5-15th January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_pickle('../data/yahoo_price.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access other attributes like `day_of_week` or `month`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.index.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the datetime is in a column instead of the index, you can use the `dt` accessor to access the datetime properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_reindex = price.reset_index()\n",
    "\n",
    "price_reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_reindex[\"Date\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the week of year from the date column and create a new column `week_of_year`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above, the dates are on business days, if you want to change the frequency to calendar days (known as resampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_resampled = price.resample('D').asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_resampled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fill the na values with the most recent value, you can use the `.ffill()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_resampled = price.resample('D').ffill()\n",
    "\n",
    "price_resampled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to resample to a lower frequency (e.g. monthly) you need to provide an aggregation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_resampled = price.resample('MS').mean()\n",
    "\n",
    "price_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more resampling frequencies options, please refer to the official [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)\n",
    "\n",
    "> Resample price to `yearly` (start of year) frequency, use `sum` as aggregation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window functions\n",
    "\n",
    "You can apply functions evaluated over a sliding window using the `rolling` method.\n",
    "\n",
    "For example, to compute the 30-day moving average for Apple price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price[\"AAPL\"].rolling(30).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, rolling functions require all of the values in the window to be non-NA. This behavior can be changed to account for missing data and, especially at the beginning of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price[\"AAPL\"].rolling(30, min_periods=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Compute a 10-day moving average for `GOOG` with a min period of 5 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining and Merging Datasets\n",
    "\n",
    "Data can be combined or merged in a number of ways:\n",
    "\n",
    "- `merge`: connects rows in DataFrames based on one or more keys. Equivalent to database `join` operations.\n",
    "- `concat`: concatenates or \"stacks\" together objects along an axis. Equivalent to database `union` operations.\n",
    "- `combine_first`: instance method enables splicing together overlapping data to fill in missing values in one object with values from another. _We went through this in unit 7_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `merge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"], \n",
    "                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
    "\n",
    "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"], \n",
    "                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the two dataframes above constitutes a _many-to-one_ join; the data in `df1` has multiple rows labeled `a` and `b`, whereas `df2` has only one row for each value in the key column `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did not specify which column(s) to join on, `merge` uses the overlapping column names as the keys. It’s a good practice to specify explicitly, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column names are different in each object, you can specify them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\"lkey\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"a\", \"b\"], \n",
    "                    \"data1\": pd.Series(range(7), dtype=\"Int64\")})\n",
    "\n",
    "df4 = pd.DataFrame({\"rkey\": [\"a\", \"b\", \"d\"], \n",
    "                    \"data2\": pd.Series(range(3), dtype=\"Int64\")})\n",
    "\n",
    "pd.merge(df3, df4, left_on=\"lkey\", right_on=\"rkey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default merge type is `inner` join. You can specify the other options- `left, right, outer` via the `how` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on=\"lkey\", right_on=\"rkey\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a _many-to-many_ join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"], \n",
    "                    \"data1\": pd.Series(range(6), dtype=\"Int64\")})\n",
    "\n",
    "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"b\", \"d\"], \n",
    "                    \"data2\": pd.Series(range(5), dtype=\"Int64\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were `three \"b\"` rows in the left DataFrame and `two` in the right one, there are `six \"b\"` rows in the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merge `df1` and `df2` with a left join. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge with multiple keys, pass a list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\"], \n",
    "                     \"key2\": [\"one\", \"two\", \"one\"],\n",
    "                     \"lval\": pd.Series([1, 2, 3], dtype='Int64')})\n",
    "\n",
    "right = pd.DataFrame({\"key1\": [\"foo\", \"foo\", \"bar\", \"bar\"],\n",
    "                      \"key2\": [\"one\", \"one\", \"one\", \"two\"],\n",
    "                      \"rval\": pd.Series([4, 5, 6, 7], dtype='Int64')})\n",
    "\n",
    "pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are overlapping non-key column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"key1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass `suffixes` to specify the strings to append to the overlaping names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"key1\", suffixes=(\"_left\", \"_right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the merge key(s) is in the index, you can pass `left_index=True` or `right_index=True` to indicate that the index should be used as the merge key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1 = pd.DataFrame({\"key\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"c\"],\n",
    "                      \"value\": pd.Series(range(6), dtype=\"Int64\")})\n",
    "\n",
    "right1 = pd.DataFrame({\"group_val\": [3.5, 7]}, index=[\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left1, right1, left_on=\"key\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame has a `join` method which performs a left join by default. The join key on the right dataframe has to be the index. The join key on the left dataframe can be an index or a column (by specifying the `on` parameter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1.join(right1, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `concat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can join DataFrames along any axis which is referred to as _concatenation_ or _stacking_. This is akin to database `union` operations, in any \"direction\" (axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1], index=[\"a\", \"b\"], dtype=\"Int64\")\n",
    "s2 = pd.Series([2, 3, 4], index=[\"c\", \"d\", \"e\"], dtype=\"Int64\")\n",
    "s3 = pd.Series([5, 6], index=[\"f\", \"g\"], dtype=\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `concat` with these objects in a list glues together the values and indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `concat` works along `axis=\"index\"`, producing another Series. If you pass `axis=\"columns\"`, the result will instead be a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behavior of `concat` is union (`outer` join) of the indexes, you can also intersect them by passing `join='inner'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = pd.concat([s1, s3])\n",
    "\n",
    "s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s4], axis=\"columns\", join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When combining Series along axis=\"columns\", pass the `keys` argument for the DataFrame column headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1, s2, s3], axis=\"columns\", keys=[\"one\", \"two\", \"three\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concat `s1`, `s2` and `s3` along index and pass `keys=[\"one\", \"two\", \"three\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DataFrames, it will become a hierarchical index instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=[\"a\", \"b\", \"c\"],\n",
    "                   columns=[\"one\", \"two\"])\n",
    "\n",
    "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=[\"a\", \"c\"], \n",
    "                   columns=[\"three\", \"four\"])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=\"columns\", keys=[\"level1\", \"level2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the index does not contain any relevant data, and you want to avoid concatenating based on indexes, you can pass the `ignore_index=True` argument, this will assign a new default index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.standard_normal((3, 4)), \n",
    "                   columns=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "df2 = pd.DataFrame(np.random.standard_normal((2, 3)), \n",
    "                   columns=[\"b\", \"d\", \"a\"])\n",
    "\n",
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concat `df1` and `df2` on the column axis but ignore the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Pivoting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping or pivoting dataframes refers to the process of changing the layout of a dataframe. This is useful when you want to change the granularity of your data or when you want to convert a _wide_ dataframe into a _long_ dataframe or vice versa.\n",
    "\n",
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)), \n",
    "                    index=pd.Index([\"Ohio\", \"Colorado\"], name=\"state\"),\n",
    "                    columns=pd.Index([\"one\", \"two\", \"three\"], name=\"number\"))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack` method pivots the columns into rows, producing a Series with a MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.stack()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a hierarchically indexed Series, you can rearrange the data back into a DataFrame with `unstack` , which pivots rows into columns.\n",
    "\n",
    "By default, the innermost level is unstacked (same with stack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can unstack a different level by passing a level number or name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just stating the name of the level\n",
    "result.unstack(level=\"state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you unstack in a DataFrame, the level unstacked becomes the lowest level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"left\": result, \"right\": result + 5},\n",
    "                  columns=pd.Index([\"left\", \"right\"], name=\"side\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=\"state\").stack(level=\"side\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting between \"Wide\" and \"Long\" Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long format and wide format are two common ways of organizing data in the context of databases, spreadsheets, or data analysis. They refer to the arrangement of data rows and columns.\n",
    "\n",
    "1. Long format\n",
    "\n",
    "Each row typically represents a single observation or entry, and each column contains variables or attributes related to that observation. This format is also known as \"tidy data\" or \"normalized data.\"\n",
    "\n",
    "Example:\n",
    "\n",
    "| Year | Country | Population |\n",
    "| ---- | ------- | ---------- |\n",
    "| 2019 | SG      | 5.7        |\n",
    "| 2019 | MY      | 31.5       |\n",
    "| 2019 | TH      | 69.8       |\n",
    "| 2020 | SG      | 5.7        |\n",
    "| 2020 | MY      | 32.7       |\n",
    "| 2020 | TH      | 69.8       |\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- It is easier to handle and analyze structured data with different attributes.\n",
    "- Efficient storage for sparse data, as it avoids repeating column headers.\n",
    "\n",
    "2. Wide format\n",
    "\n",
    "Each row contains multiple observations or entries, and each column contains variables or attributes related to that observation.\n",
    "\n",
    "Example:\n",
    "\n",
    "| Year | SG   | MY   | TH   |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| 2019 | 5.7  | 31.5 | 69.8 |\n",
    "| 2020 | 5.7  | 32.7 | 69.8 |\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Easier to read and understand when the number of variables is limited.\n",
    "- Suitable for simple summary statistics and basic analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_reindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"pivot\" a table from a \"wide\" format to a \"long\" format using the `melt` function.\n",
    "\n",
    "The `date` column is the group indicator, while the other columns are data values. We need to indicate the group indicator(s):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = pd.melt(price_reindex, id_vars=\"Date\")\n",
    "\n",
    "melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rerun `melt` and pass arguments such that the new columns are named `Company` and `Price` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pivot`, we can reshape back to the original layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = melted.pivot(index='Date', columns='variable', values='value')\n",
    "\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data aggregation is the process of grouping data together and performing calculations on them. It is equivalent to the `GROUP BY` clause in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key1\" : [\"a\", \"a\", None, \"b\", \"b\", \"a\", None], \n",
    "                   \"key2\" : pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "                   \"data1\" : np.random.standard_normal(7), \n",
    "                   \"data2\" : np.random.standard_normal(7)})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compute the mean for each unique value in `key1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key1\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not make sense to compute the mean for `key2` since it is a categorical variable and also serves as a key.\n",
    "\n",
    "We can select the numeric columns to compute the mean for (after the `groupby` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key1\")[[\"data1\", \"data2\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following also works, since the returned result is a DataFrame, however it is less efficient as the selection/subset happens after the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key1\").mean()[[\"data1\", \"data2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can group by more than 1 column. There is a useful GroupBy method `size` which returns a Series containing group sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also group by other `Series`/`array`/`list` with the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\n",
    "years = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n",
    "\n",
    "df[\"data1\"].groupby([states, years]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For built-in aggregation methods in pandas, refer to the [documentation](https://pandas.pydata.org/docs/user_guide/groupby.html#built-in-aggregation-methods).\n",
    "\n",
    "> Group by `key1` and `key2` and compute the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your own aggregation functions, pass any function that aggregates an array to the `aggregate` method or its short alias `agg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"key1\")\n",
    "\n",
    "grouped.agg(peak_to_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a list of functions, or function names (for built-in functions) to `aggregate`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg([peak_to_peak, \"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "The most general-purpose GroupBy method is `apply`, which splits the object being manipulated into pieces, invokes the passed function on each piece, and then concatenates the pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv(\"../data/tips.csv\")\n",
    "\n",
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with the tip percentage\n",
    "\n",
    "tips[\"tip_pct\"] = tips[\"tip\"] / tips[\"total_bill\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to select the top five `tip_pct` values by group. First, write a function that selects the rows with the largest values in a particular column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(df, n=5, column=\"tip_pct\"):\n",
    "    return df.sort_values(column, ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top(tips, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then `apply` this function by different groups using `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(\"smoker\").apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass the arguments to the function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby([\"smoker\", \"day\"]).apply(top, n=2, column=\"total_bill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apply the function on `day` and `time` group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create a function that selects the bottom five `tip_pct` values.\n",
    ">\n",
    "> Then apply it on `smoker` group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "\n",
    "You can also transform your data using the `transform` method. It is similar to `apply` but imposes more restrictions on the type of function you can use. The function must:\n",
    "\n",
    "- Produce a scalar value to be broadcast to the shape of the group chunk, or\n",
    "- Return an object that is the same shape as the group chunk\n",
    "- Not mutate its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['a', 'b', 'c'] * 4, 'value': np.arange(12.)})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby('key')['value']\n",
    "\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform` produce a Series of the same shape as `df['value']` but with values replaced by the average grouped by `key`.\n",
    "\n",
    "We can pass a function or function name (for built-in aggregation) to `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.transform(lambda g: g.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_two(group):\n",
    "    return group * 2\n",
    "\n",
    "g.transform(times_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common transformation in data analytics / science is _standardization_ or _standard scaling_. This is where we transform the data to have a mean of 0 and a standard deviation of 1. It is also known as _z-score normalization_.\n",
    "\n",
    "The formula for standard scaling is:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where $x$ is the value, $\\mu$ is the mean, and $\\sigma$ is the standard deviation.\n",
    "\n",
    "We can achieve this using `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "g.transform(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the following works too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = (df['value'] - g.transform('mean')) / g.transform('std')\n",
    "\n",
    "standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables and Cross-Tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table is a data summarization tool that is used in the context of data processing. Pivot tables are used to summarize, sort, reorganize, group, count, total or average data. It allows its users to transform columns into rows and rows into columns. It allows grouping by any data field.\n",
    "\n",
    "In pandas, you can use the `pivot_table` method which is made possible through the `groupby` and `reshape` operations utilizing hierarchical indexing. In addition, `pivot_table` can add partial totals, also known as _margins_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default aggregation for `pivot_table` is mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"day\", \"smoker\"], values=[\"size\", \"tip\", \"tip_pct\", \"total_bill\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can put `smoker` in the table columns and `time` and `day` in the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\", \n",
    "                 values=[\"tip_pct\", \"size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add partial totals by passing `margins=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\", \n",
    "                 values=[\"tip_pct\", \"size\"], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use other aggregation functions, pass it to the `aggfunc` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"time\", \"smoker\"], columns=\"day\", \n",
    "                 values=\"tip_pct\", aggfunc=len, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `fill_value` to fill missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"time\", \"smoker\"], columns=\"day\", \n",
    "                 values=\"tip_pct\", aggfunc=len, margins=True, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Compute the sum of `tip` in a pivot table with `day` and `time` in the rows and `smoker` in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _cross-tabulation_ or _crosstab_ is a special case of pivot table that computes group frequencies (counts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=[tips[\"time\"], tips[\"day\"]], columns=tips[\"smoker\"], margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
